{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/zaid/anaconda3/envs/QATM/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zaid/anaconda3/envs/QATM/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zaid/anaconda3/envs/QATM/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zaid/anaconda3/envs/QATM/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zaid/anaconda3/envs/QATM/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zaid/anaconda3/envs/QATM/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Lambda, Concatenate\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4 1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__, tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import QATM, MyNormLayer\n",
    "from utils import compute_score, locate_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = 'test3'\n",
    "gt = sorted([ os.path.join(file_dir, i) for i in os.listdir(file_dir)  if '.txt' in i ])\n",
    "img_path = sorted([ os.path.join(file_dir, i) for i in os.listdir(file_dir) if '.jpg' in i ] )\n",
    "def read_gt( file_path ):\n",
    "    with open( file_path ) as IN:\n",
    "        x, y, w, h = [ eval(i) for i in IN.readline().strip().split(',')]\n",
    "    return x, y, w, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model( featex, alpha = 1. ):\n",
    "    T = Input( (None, None, 3), name='template_input' )\n",
    "    I = Input( (None, None, 3), name='image_input' )\n",
    "    T_feat = featex(T)\n",
    "    I_feat = featex(I)\n",
    "    I_feat, T_feat = MyNormLayer( name='norm_layer' )( [I_feat, T_feat] )\n",
    "    dist = Lambda( lambda x: tf.einsum( \"xabc,xdec->xabde\", K.l2_normalize(x[0], axis=-1), K.l2_normalize(x[1], axis=-1) ) , name=\"cosine_dist\")([ I_feat, T_feat ])\n",
    "    conf_map = QATM(alpha, name='qatm')( dist )\n",
    "    return Model( [T, I], [conf_map], name='QATM_model' )\n",
    "def model_eval( featex, alpha=1., backup=None ):\n",
    "    '''\n",
    "    Have a backup featex in case image is too big.\n",
    "    '''\n",
    "    model = create_model( featex , alpha=alpha)\n",
    "    if backup is not None:\n",
    "        model_bkup = create_model( backup , alpha=alpha)\n",
    "    else:\n",
    "        model_bkup = model\n",
    "    gt_list, gray_list, score_list = [], [], []\n",
    "\n",
    "    num_samples = len(img_path) // 2\n",
    "    bar = progressbar.ProgressBar(max_value=num_samples)\n",
    "    for idx in range(num_samples):\n",
    "        bar.update(idx + 1)\n",
    "        # load image and ground truth\n",
    "        template_raw = cv2.imread( img_path[2*idx] )[...,::-1]\n",
    "        template_bbox = read_gt( gt[2*idx] )\n",
    "        x, y, w, h = [int(round(t)) for t in template_bbox]\n",
    "        template = template_raw[y:y+h, x:x+w]\n",
    "        image = cv2.imread( img_path[2*idx+1] )[...,::-1]\n",
    "        image_gt = read_gt( gt[2*idx+1] )\n",
    "        x_gt, y_gt, w_gt, h_gt = [int(round(t)) for t in image_gt]\n",
    "        \n",
    "        # process images\n",
    "        template_ = np.expand_dims(preprocess_input( template ), axis=0)\n",
    "        image_ = np.expand_dims(preprocess_input( image ) , axis=0)\n",
    "        if w*h <= 4000:\n",
    "            val = model.predict( [template_, image_] )\n",
    "        else:\n",
    "            # used when image is too big\n",
    "            val = model_bkup.predict( [template_, image_] )\n",
    "        \n",
    "        # compute geometry mean on score map\n",
    "        val = np.log( val )\n",
    "        gray = val[0,:,:,0]\n",
    "        gray = cv2.resize( gray, (image.shape[1], image.shape[0]) )\n",
    "        score = compute_score( gray, w_gt, h_gt )\n",
    "        score[score>-1e-7] = -np.inf\n",
    "        \n",
    "        gt_list.append( image_gt )\n",
    "        gray_list.append( gray )\n",
    "        score_list.append( score )\n",
    "    return score_list, gt_list, gray_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = keras.applications.vgg19.VGG19( include_top = False, weights = 'imagenet' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize conv3_4 to conv1_2\n",
    "input_ = vgg19.input\n",
    "conv1_2 = vgg19.get_layer('block1_conv2').output\n",
    "conv3_4 = vgg19.get_layer('block3_conv4').output\n",
    "conv3_4 = Lambda( lambda x: tf.image.resize_bilinear( x[0], size=(tf.shape(x[1])[1], tf.shape(x[1])[2]), align_corners=True), name='resized_image' )( [conv3_4, conv1_2] )\n",
    "concat = Concatenate()( [conv1_2, conv3_4] )\n",
    "featex = Model( [input_], [concat], name='featex' )\n",
    "# resize conv1_2 to conv3_4, used when image size is too big\n",
    "input_ = vgg19.input\n",
    "conv1_2 = vgg19.get_layer('block1_conv2').output\n",
    "conv3_4 = vgg19.get_layer('block3_conv4').output\n",
    "conv1_2 = Lambda( lambda x: tf.image.resize_bilinear( x[1], size=(tf.shape(x[0])[1], tf.shape(x[0])[2]), align_corners=True), name='resized_image' )( [conv3_4, conv1_2] )\n",
    "concat = Concatenate()( [conv1_2, conv3_4] )\n",
    "featex2 = Model( [input_], [concat], name='featex2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model( featex , alpha=25)\n",
    "model_bkup = create_model( featex2 , alpha=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_sample( idx=0 ):\n",
    "    '''\n",
    "    idx: index of image in OTB dataset, from 0 to 104\n",
    "    '''\n",
    "    # load image and ground truth\n",
    "    template_raw = cv2.imread( img_path[1*idx] )[...,::-1]\n",
    "    template_bbox = read_gt( gt[1*idx] )\n",
    "    x, y, w, h = [int(round(t)) for t in template_bbox]\n",
    "    template_plot = cv2.rectangle( template_raw.copy(), (x, y), (x+w, y+h), (0, 255,0), 2 )\n",
    "    template = template_raw[y:y+h, x:x+w]\n",
    "    \n",
    "    \n",
    "    image = cv2.imread( img_path[1*idx+1] )[...,::-1]\n",
    "    print(img_path[1*idx],img_path[1*idx+1] )\n",
    "    image_gt = read_gt( gt[1*idx+1] )\n",
    "    x, y, w, h = [int(round(t)) for t in image_gt]\n",
    "    image_plot = cv2.rectangle( image.copy(), (x, y), (x+w, y+h), (0, 255, 0), 2 )\n",
    "    \n",
    "    # process images\n",
    "    template_ = np.expand_dims(preprocess_input( template ), axis=0)\n",
    "    image_ = np.expand_dims(preprocess_input( image ) , axis=0)\n",
    "    if w*h <= 4000:\n",
    "        print('if running')\n",
    "        val = model.predict( [template_, image_] )\n",
    "    else:\n",
    "        print('else running')\n",
    "        # used when image is too big\n",
    "        val = model_bkup.predict( [template_, image_] )\n",
    "\n",
    "    # compute geometry average on score map\n",
    "    val = np.log( val )\n",
    "    gray = val[0,:,:,0]\n",
    "    gray = cv2.resize( gray, (image.shape[1], image.shape[0]) )\n",
    "    score = compute_score( gray, w, h ) \n",
    "    score[score>-1e-7] = score.min()\n",
    "    score = np.exp(score / (h*w)) # reverse number range back after computing geometry average\n",
    "    \n",
    "    # plot result\n",
    "    x, y, w, h = locate_bbox( score, w, h )\n",
    "    image_plot = cv2.rectangle( image_plot, (int(x), int(y)), (int(x+w), int(y+h)), (255, 0, 0), 2 )\n",
    "    fig, ax = plt.subplots( 1, 3, figsize=(20, 5) )\n",
    "    ax[0].imshow(template_plot)\n",
    "    ax[1].imshow(image_plot)\n",
    "    \n",
    "    ax[2].imshow(score, 'jet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_one_sample(idx=5) # green: ground truth, red: prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QATM",
   "language": "python",
   "name": "qatm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
